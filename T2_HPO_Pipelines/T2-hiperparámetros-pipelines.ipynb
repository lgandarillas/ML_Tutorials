{"cells":[{"cell_type":"markdown","source":["# Manejo con pipelines\n","\n","En este tutorial aprenderemos a trabajar con pipelines y lo mezclaremos con estrategias de optimización de parámetros.\n","\n","Usaremos el dataset del Titanic donde nos encontraremos con los siguientes temas:\n","   - Habrá variables nulas\n","   - Tendremos variables categóricas y numéricas\n","   - El dataset se encuentra desbalanceado\n"],"metadata":{"id":"E0d1NdTBxjrd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJJr_V0rgGRx"},"outputs":[],"source":["%matplotlib inline\n","#######\n","# Importamos todas las dependencias\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.datasets import fetch_openml\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder\n","#from sklearn.ensemble import RandomForestClassifier\n","from sklearn import tree\n","from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n","from sklearn import metrics\n","\n","np.random.seed(42)\n","\n","X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n","X.head(10)"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["y.value_counts()"],"metadata":{"id":"7xztMyaLK_RV"}},{"cell_type":"markdown","source":["Como vemos este dataset se encuentra algo desbalanceado. Lo tendremos que tener en cuenta en los siguientes momentos:\n","   - Al dividir en muestras de aprendizaje y test\n","   - Cuando usemos Cross Validation\n","   - En el entrenamiento de los modelos. Casi todos los métodos en sklearn admiten un parámetro `class_weight='balanced'`"],"metadata":{"collapsed":false,"id":"bBuQfsrhK_RW"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# Borramos columnas que no nos interesan\n","X.drop(['boat', 'body', 'home.dest', 'ticket', 'name'], axis=1, inplace=True)\n","# Seleccionados train/test en modo stratify, ya que el dataset se encuentra desbalanceado\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"],"metadata":{"id":"fOajKItXK_RW"}},{"cell_type":"code","source":["X.describe()"],"metadata":{"id":"971JPXiuhSZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tratamiento de valores nulos"],"metadata":{"id":"3i24oFW7O2jC"}},{"cell_type":"code","source":["X_train.isnull().any()"],"metadata":{"id":"FEqLv3HohRi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.isnull().sum()"],"metadata":{"id":"rkwrzzkVhqaJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a dibujar los valores que son nulos"],"metadata":{"id":"OWop5l_7PGyR"}},{"cell_type":"code","source":["import missingno as msno\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'png'\n","\n","msno.matrix(X_train)\n","plt.show()"],"metadata":{"id":"Elk-mLoDhxyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.isnull().sum() / len(X_train) * 100"],"metadata":{"id":"Tgb5bJGoh7kr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El atributo 'cabin' tiene demasiados valores nulos. En este caso no tiene sentido aplicar ningún método de imputación, por lo que vamos a eliminar"],"metadata":{"id":"Q2PAd5S_Pdkc"}},{"cell_type":"code","source":["X_train.drop(['cabin'], axis=1, inplace=True)\n","X_test.drop(['cabin'], axis=1, inplace=True)"],"metadata":{"id":"BTjHdvf8iDLi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a calcular las correlaciones de los valores numéricos"],"metadata":{"id":"fMpNwwfzP-GG"}},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","%config InlineBackend.figure_format = 'svg'\n","\n","X_comb = pd.concat([X_train, y_train.astype(float)], axis=1)\n","g = sns.heatmap(X_comb[['pclass', 'age', 'sibsp', 'parch', 'fare', 'survived']].corr(),\n","                annot=True,\n","                cmap = \"coolwarm\")"],"metadata":{"id":"Z_Vm4bCciI1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Si fuera tipo objeto evaluar \"OrdinalEncoder\"\n","X['pclass'].value_counts()"],"metadata":{"id":"mZYy3NN_qXuK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Codificamos la salida\n","Aunque la variable de salida es 0 y 1, pasamos a codificarla con `LabelEncoder` ya que para algunas funciones como el cálculo de las curvas ROC necesitamos esta codificación."],"metadata":{"id":"Bp-iTRmzRo6l"}},{"cell_type":"code","source":["# Es necesario\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","le.fit(y)\n","\n","y_test = le.transform(y_test)\n","y_train = le.transform (y_train)"],"metadata":{"id":"Has35auCRTT7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Analizar tipos de variables\n","Vamos a analizar las variables categóricas que tenemos en el dataset"],"metadata":{"id":"W3O--NolMH0m"}},{"cell_type":"code","source":["X_train.dtypes"],"metadata":{"id":"_Q1FfeSrMTZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_cols = X_train.select_dtypes(include=\"category\").columns\n","num_cols = X_train.select_dtypes(exclude=\"category\").columns"],"metadata":{"id":"Y1E33baKM6a4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_cols"],"metadata":{"id":"IJ6rANfKHjvJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para las variables categóticas vamos a crear un pipeline donde:\n","1. Si hubiese una muestra con valores nulos, le vamos a imputar el valor del más frecuente.\n","2. Codificaremos con la técnicas One_Hot_Encoder.\n","3. Aplicaremos sobre ellos un PCA, para extraer características más discriminantes"],"metadata":{"id":"Sb_hq9qHOQMh"}},{"cell_type":"code","source":["cat_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n","    ('pca', PCA(n_components=5))\n","])"],"metadata":{"id":"kSoYVcK9OPH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Si queremos acceder al primer paso del pipeline. De la misma forma podríamos acceder a los distintos pasos del pipeline\n","cat_transformer[0]"],"metadata":{"id":"Vuhr22iKkfmp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora nos metemos con las variables numéricas. En este caso vamos a realizar el siguiente preproceso:\n","1. Si hay valores nulos, vamos a asignarles la media de sus K=5 vecinos más cercanos.\n","2. Realizaremos un escalado"],"metadata":{"id":"uw9PqZd8PkU2"}},{"cell_type":"code","source":["from sklearn.impute import KNNImputer\n","from sklearn.preprocessing import RobustScaler\n","\n","num_transformer = Pipeline(steps=[\n","    ('imputer', KNNImputer(n_neighbors=5)),\n","    ('scaler', RobustScaler())\n","])"],"metadata":{"id":"xWufY9ZVko5q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En el siguiente código vamos a utilizar la función `ColumnTransformer` para indicar cómo vamos a preprocesar a las variables categóricas y numéricas"],"metadata":{"id":"kYV8YA2SQY46"}},{"cell_type":"code","source":["preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', num_transformer, num_cols),\n","        ('cat', cat_transformer, cat_cols)\n","    ])\n",""],"metadata":{"id":"lMSjq_zflPTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preprocessor\n"],"metadata":{"id":"PcANmNg0n6xo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creamos el clasificador\n","Por último, vamos a crear un `Pipeline` para unir el paso del preproceso, con el paso de entrenamiento del modelo. Fijaros que en el entrenamiento del modelo estoy indicando `class_weight='balanced'`, ya que el dataset se encuentra desbalanceado."],"metadata":{"id":"_5fnpkS-QqeY"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('classifier', tree.DecisionTreeClassifier(class_weight='balanced'))])"],"metadata":{"id":"GG_27e0Ulcpx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Si el valor del parámetro es `cv` asignado a un número entero y la variable de salida es binaria o multiclase, entonces utiliza `StratifiedKFold`. Directamente utiliza el valor de `shuffle=False`.\n","En este caso, lleva a cabo un `StratifiedKFold` con K=5, y obtenemos el valor medio del `accuracy`."],"metadata":{"id":"7mWd0PHbSZv0"}},{"cell_type":"code","source":["clf"],"metadata":{"id":"bqS6zIyjoCto"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como el dataset está desbalanceado usamos como mejor resultado \"balanced_accuracy\""],"metadata":{"id":"urFPio77HbaN"}},{"cell_type":"code","source":["cross_val_score(clf, X_train, y_train, cv=5, scoring=\"balanced_accuracy\").mean()"],"metadata":{"id":"FP6hyBo-RmU1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora vamos a buscar los mejores hiperparámetros"],"metadata":{"id":"yg_qfaXqHBSn"}},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","num_transformer_dist = {'preprocessor__num__imputer__n_neighbors': list(range(2, 15)),\n","                        'preprocessor__num__imputer__add_indicator': [True, False]}\n","\n","cat_transformer_dist = {'preprocessor__cat__imputer__strategy': ['most_frequent', 'constant'],\n","                        'preprocessor__cat__imputer__add_indicator': [True, False],\n","                        'preprocessor__cat__pca__n_components': list(range(2, 5))}\n","\n","random_forest_dist = {'classifier__max_depth': list(range(2, 20)),\n","                      'classifier__min_samples_split': list(range(20, 200))}\n","\n","param_dist = {**num_transformer_dist, **cat_transformer_dist, **random_forest_dist}\n","\n","random_search = RandomizedSearchCV(clf,\n","                                   param_distributions=param_dist,\n","                                   n_iter=100)"],"metadata":{"id":"kYJaAPBfl0uW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random_search.fit(X_train, y_train)"],"metadata":{"id":"1OAJzeDGmHUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random_search.best_score_"],"metadata":{"id":"VE0x64a3mTVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random_search.best_params_"],"metadata":{"id":"igX9CT-8nu5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = random_search.predict(X_test)\n","y_pred[:10]"],"metadata":{"id":"035RnFOnn17o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred))"],"metadata":{"id":"os1939zRn8aB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La precisión balanceada se usa en problemas de clasificación binaria y multiclase para tratar conjuntos de datos desbalanceados. Se define como la media del recall obtenido en cada clase."],"metadata":{"id":"STUbZIRxvBY4"}},{"cell_type":"code","source":["from sklearn.metrics import balanced_accuracy_score\n","\n","print(f\"El valor de balanced accuracy: {balanced_accuracy_score(y_test, y_pred)}\")\n"],"metadata":{"id":"fqePw5ewoDa2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","\n","cm = confusion_matrix(y_test, y_pred, labels=random_search.classes_)\n","disp= ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=random_search.classes_)\n","disp.plot()\n","plt.show()"],"metadata":{"id":"Da3zOsj9oI2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Obtenemos las curva ROC y el área bajo la curva (AUC)\n","\n","probs = random_search.predict_proba(X_test)[:, 1]\n","\n","auc = metrics.roc_auc_score(y_test, probs)\n","fpr, tpr, thresholds = metrics.roc_curve(y_test, probs)\n","\n","plt.figure(figsize=(8, 5))\n","plt.plot(fpr, tpr, label=f'AUC  = {auc:.2f}')\n","plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Baseline')\n","plt.title('Curva ROC', size=20)\n","plt.xlabel('Falsos Positivos', size=14)\n","plt.ylabel('Verdaderos Positivos', size=14)\n","plt.legend();"],"metadata":{"id":"v0p09VIRON_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modelo final\n","modelo_final = random_search.best_estimator_\n","_ = modelo_final.fit (X,y)\n"],"metadata":{"id":"DAa7z4-4PFfi"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}