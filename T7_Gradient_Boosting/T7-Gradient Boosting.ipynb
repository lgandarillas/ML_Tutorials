{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_jEsE8W6HbZ"
   },
   "source": [
    "# Gradient Boosting Trees\n",
    "\n",
    "En este tutorial trabajaremos con los modelos basados en Gradiente Boosting Trees. A parte de trabajar con las implementaciones de *sklearn* `HistGradientBoosting`, veremos otras implementaciones de *XGBoost*, y *LightGBM*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos con el dataset \"adult\" que intenta clasificar si una persona gana más de 50K$ al año en base a ciertas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"adult\", version=2, return_X_y=True)\n",
    "\n",
    "# Quitamos dos columnas:\n",
    "# - \"education-num\" porque es redundante con \"education\"\n",
    "# - \"fnlwgt\" (peso final) porque no se sabe qué significa\n",
    "X = X.drop([\"education-num\", \"fnlwgt\"], axis=\"columns\")\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que tenemos variables categóricas y numéricas. En nuestras versiones de Gradient Boosting Trees no va a ser un problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que también existen \"missing values\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un problema desbalanceado, tomaremos algunas medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7PQK5_08EYF"
   },
   "outputs": [],
   "source": [
    "# Holdout para la evaluación del modelo. 33% de los datos disponibles para test\n",
    "# Este sería la evalución outer loop\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.33, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpkoVv3l-GjJ"
   },
   "source": [
    "# HistGradientBoostingClassifier\n",
    "Los parámetros más importantes de la implantación de sklearn (`HistGradientBoostingClassifier`) para controlar el crecimiento de los árboles, la velocidad de aprendizaje del modelo, y los que gestionan la parada temprana para evitar *overfitting*, son:\n",
    "\n",
    "- `learning_rate`: reduce la contribución de cada árbol multiplicando su influencia original por este valor.\n",
    "- `max_iter`: El número máximo de iteraciones del proceso de boosting, es decir, el número máximo de árboles.\n",
    "- `max_depth`: profundidad máxima que pueden alcanzar los árboles.\n",
    "- `min_samples_split`: número mínimo de observaciones que debe de tener un nodo para que pueda dividirse. Si es un valor decimal se interpreta como fracción del total de observaciones de entrenamiento `ceil(min_samples_split * n_samples)`.\n",
    "- `min_samples_leaf`: número mínimo de observaciones que debe de tener cada uno de los nodos hijos para que se produzca la división. Si es un valor decimal se interpreta como fracción del total de observaciones de entrenamiento `ceil(min_samples_split * n_samples)`.\n",
    "- `validation_fraction`: proporción de datos separados del conjunto entrenamiento y empleados como conjunto de validación para determinar la parada temprana (*early stopping*).\n",
    "- `n_iter_no_change`: número de iteraciones consecutivas en las que no se debe superar el tol para que el algoritmo se detenga (*early stopping*). Si su valor es None se desactiva la parada temprana.\n",
    "- `tol`: porcentaje mínimo de mejora entre dos iteraciones consecutivas por debajo del cual se considera que el modelo no ha mejorado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "executionInfo": {
     "elapsed": 2148,
     "status": "ok",
     "timestamp": 1678388945885,
     "user": {
      "displayName": "MIGUEL ANGEL PATRICIO GUISADO",
      "userId": "13328848534964446801"
     },
     "user_tz": -60
    },
    "id": "XeXx3Bsf-LAF",
    "outputId": "6f25e317-787c-461e-d419-b61e46984712"
   },
   "outputs": [],
   "source": [
    "# Creación del modelo (ATENCION: este modelo admite variables categóricas y numéricas)\n",
    "# categorical_features=\"from_dtype\" indica que las variables categóricas son las que \n",
    "# son de tipo object\n",
    "# ==============================================================================\n",
    "cls_gb = HistGradientBoostingClassifier(\n",
    "            categorical_features=\"from_dtype\",\n",
    "            random_state = 42\n",
    "         )\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "# ==============================================================================\n",
    "np.random.seed(42)\n",
    "cls_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "y_test_pred = cls_gb.predict(X_test)\n",
    "result = metrics.classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzTsNGzbUxkg"
   },
   "source": [
    "## Búsqueda de parámetros con Random Search\n",
    "Vamos a realizar una búsqueda usando Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy4hijlzVLJg",
    "outputId": "4bcb0bdb-1616-4684-9478-9bbc3fd2ad73"
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth'         : [None, 1, 3, 5, 10, 20, 30],\n",
    "              'max_iter'          : sp_randint(50, 500),\n",
    "              'learning_rate'     : [0.001, 0.01, 0.1, 0.2],\n",
    "              'l2_regularization' : [0, 1],\n",
    "              'max_leaf_nodes'    : [3, 10, 30, 40]\n",
    "             }\n",
    "\n",
    "inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "budget = 20\n",
    "# Cross-validation (3-fold) para la búsqueda de hiper-parámetros\n",
    "clf = RandomizedSearchCV (estimator  = HistGradientBoostingClassifier(\n",
    "                                max_iter            = 1000,\n",
    "                                random_state        = 42,\n",
    "                                categorical_features=\"from_dtype\",\n",
    "                                # Activación de la parada temprana\n",
    "                                validation_fraction = 0.1,\n",
    "                                n_iter_no_change    = 5,\n",
    "                                tol                 = 0.0001),\n",
    "                           param_distributions = param_grid,\n",
    "                           scoring='balanced_accuracy',\n",
    "                           cv=inner,\n",
    "                           refit=True,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1,\n",
    "                           n_iter=budget,\n",
    "                           return_train_score=True)\n",
    "\n",
    "np.random.seed(42)\n",
    "clf.fit(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(clf.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = clf.best_estimator_\n",
    "y_test_pred = modelo_final.predict(X_test)\n",
    "result = metrics.classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPzAuxbZMt7n"
   },
   "source": [
    "## Importancia por permutación\n",
    "Identifica la influencia que tiene cada predictor sobre una determinada métrica de evaluación del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2jpNEXoz3Zp"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "\n",
    "importancia = permutation_importance(\n",
    "                estimator    = modelo_final,\n",
    "                X            = X_train,\n",
    "                y            = y_train,\n",
    "                n_repeats    = 5,\n",
    "                scoring      = 'accuracy',\n",
    "                n_jobs       = multiprocessing.cpu_count() - 1,\n",
    "                random_state = 42\n",
    "             )\n",
    "\n",
    "# Se almacenan los resultados (media y desviación) en un dataframe\n",
    "df_importancia = pd.DataFrame(\n",
    "                    {k: importancia[k] for k in ['importances_mean', 'importances_std']}\n",
    "                 )\n",
    "\n",
    "df_importancia['feature'] = X_train.columns\n",
    "df_importancia.sort_values('importances_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEXwhPuk0YsA"
   },
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "df_importancia = df_importancia.sort_values('importances_mean', ascending=True)\n",
    "ax.barh(\n",
    "    df_importancia['feature'],\n",
    "    df_importancia['importances_mean'],\n",
    "    xerr=df_importancia['importances_std'],\n",
    "    align='center',\n",
    "    alpha=0\n",
    ")\n",
    "ax.plot(\n",
    "    df_importancia['importances_mean'],\n",
    "    df_importancia['feature'],\n",
    "    marker=\"D\",\n",
    "    linestyle=\"\",\n",
    "    alpha=0.8,\n",
    "    color=\"r\"\n",
    ")\n",
    "ax.set_title('Importancia de los predictores (train)')\n",
    "ax.set_xlabel('Incremento del error tras la permutación');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnhcuwuydU0M"
   },
   "source": [
    "# XGBoost\n",
    "Existe un API que recubre la librería original para que tenga parámetros y métodos similares a Scikit-Learn. Los parámetros más relevantes son:\n",
    "\n",
    "- `n_estimators` (int) – Número de árboles usados. Equivalente al número de rondas de boosting.\n",
    "- `max_depth` (Optional[int]) – Máxima profundidad de los árboles.\n",
    "- `subsample` (Optional[0-1]) - Proporción de submuestreo de las instancias de entrenamiento. Si se establece en 0.5, XGBoost muestreará aleatoriamente la mitad de los datos de entrenamiento antes de hacer crecer los árboles, lo que evitará el sobreajuste. El submuestreo se realizará una vez en cada iteración de boosting.\n",
    "- `learning_rate` (Optional[float]) – Indice de aprendizaje en el Boosting  (xgb’s “eta”). Es un valor de regularización/penalización para evitar sobreajuste, limitando la influencia de cada modelo en el conjunto del ensemble\n",
    "- `booster` (Optional[str]) – Especifica el modelo a utilizar: gbtree, gblinear or dart.\n",
    "- `gamma` (Optional[float]) – (min_split_loss) Reducción mínima del error necesario para realizar otra partición en un nodo hoja del árbol.\n",
    "- `grow_policy` – Política de crecimiento del árbol. 0: favorece la división en los nodos más cercanos al nodo, es decir, crece en profundidad. 1: favorece la división en los nodos con mayor cambio del error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación XGBoost: !pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en XGBoost no se pueden tener variables de salida categóricas,\n",
    "# se deben codificar como enteros\n",
    "# ==============================================================================\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "y_test_xg = le.transform(y_test)\n",
    "y_train_xg = le.transform (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espacio de búsqueda\n",
    "param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "              'subsample'        : [0.5, 1],\n",
    "              'learning_rate'    : [0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "              'n_estimators'     : sp_randint(50, 500)\n",
    "              }\n",
    "\n",
    "# Búsqueda por random search con validación cruzada\n",
    "# ==============================================================================\n",
    "inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "budget = 20\n",
    "grid = RandomizedSearchCV(\n",
    "    estimator  = XGBClassifier(random_state = 42,enable_categorical=True),\n",
    "    param_distributions= param_grid,\n",
    "    scoring    = 'balanced_accuracy',\n",
    "    n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "    cv         = inner,\n",
    "    refit      = True,\n",
    "    verbose    = 0,\n",
    "    n_iter=budget\n",
    ")\n",
    "\n",
    "grid.fit(X = X_train, y = y_train_xg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = grid.best_estimator_\n",
    "y_test_pred = modelo_final.predict(X_test)\n",
    "result = metrics.classification_report(y_test_xg, y_test_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n",
    "Se trata de un algoritmo de Boosting con rendimientos similares a XGBoost de forma más rápida. Parámetros más relevantes:\n",
    "- `n_estimators` (int) – Número de árboles usados. Equivalente al número de rondas de boosting.\n",
    "- `max_depth` (Optional[int]) – Máxima profundidad de los árboles. (<=0 indica que no hay límite)\n",
    "- `subsample` (Optional[0-1]) - (o bagging_fraction) para especificar el porcentaje de muestras utilizadas por iteración de construcción del árbol. Esto significa que algunas filas se seleccionarán aleatoriamente para ajustar cada árbol. Esto mejora la generalización y  la velocidad de entrenamiento.\n",
    "- `learning_rate` (Optional[float]) – Indice de aprendizaje en el Boosting. Es un valor de regularización/penalización para evitar sobreajuste, limitando la influencia de cada modelo en el conjunto del ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!conda install -c conda-forge lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "  \n",
    "param_grid = {'num_leaves'       : [15, 31, 63],\n",
    "              'max_depth'        : [-1, 10, 20, 30],\n",
    "              'subsample'        : [0.5, 1],\n",
    "              'learning_rate'    : [0.01, 0.1, 0.2],\n",
    "              'n_estimators'     : [20, 40, 100, 200]\n",
    "             }\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "budget = 10\n",
    "\n",
    "# Set up the random search with cross-validation\n",
    "grid = RandomizedSearchCV(LGBMClassifier(n_estimators=1000, random_state=42), \n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=budget,\n",
    "                                   scoring = 'balanced_accuracy', \n",
    "                                   cv=inner, \n",
    "                                   n_jobs = - 1,\n",
    "                                   verbose=0,\n",
    "                                   return_train_score = True, \n",
    "                                   random_state=42)\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = grid.best_estimator_\n",
    "y_test_pred = modelo_final.predict(X_test)\n",
    "result = metrics.classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_final = grid.best_estimator_\n",
    "# Entrenamos con todos los datos para el modelo final\n",
    "_ = modelo_final.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
